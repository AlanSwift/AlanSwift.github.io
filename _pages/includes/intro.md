
I am now working on building the cutting-edge multimodal LLM at Bytedance Seed. 

<font color="red">I am looking for interns to work with me on multimodal LLM. Feel free to <a href="mailto:shenkai@zju.edu.cn">contact me</a> if you are interested!</font>

I obtained my Ph.D. degree at Zhejiang University, supervised by [Prof. Siliang Tang（汤斯亮）](https://person.zju.edu.cn/siliang/684099.html) and [Prof. Yueting Zhuang（庄越挺）](https://person.zju.edu.cn/yzhuang). I also collaborate with [Xu Tan (谭旭)](https://www.microsoft.com/en-us/research/people/xuta/) from Microsoft Research Asia and [Lingfei Wu (吴凌飞)](https://sites.google.com/a/email.wm.edu/teddy-lfwu/) closely.

My research interest includes multimodal LLM, Text-to-Speech Synthesis, ASR Error Correction, Graph Neural Network and Neural Machine Translation. I have published 10+ papers includes ICML, ICLR, NeurIPS, EMNLP, IJCAI, et.al.

I have developed: 1. the large-scale non-autoregressive text-to-Speech synthesis system [NaturalSpeech 2](https://speechresearch.github.io/naturalspeech2/) and the advanced version [NaturalSpeech 3](https://speechresearch.github.io/naturalspeech3/) when in MSRA; 2. the SOTA audio foundation model [Kimi-Audio](https://github.com/MoonshotAI/Kimi-Audio) when in Moonshot.AI.

